# Answer First

**Framework:** Ian McAllister (Dir PM @ Uber, ex-Amazon)

**Core Principle:** Answer the exact question in the first sentence, then provide context.

---

## 2-Minute Summary

**The problem:** Context-first answers bury the point, slow decisions, and erode trust.

**The solution:** BLUF (Bottom Line Up Front) - lead with your answer, then explain.

**The framework:**
- Answer the question directly (1 sentence)
- Evidence supporting your answer (2-3 bullets)
- Recommendation or next step (1 sentence)

**Quick test:** If someone only reads your first sentence, do they know the answer?

---

## The Insight

> "The top 1% of PMs answer first, then explain. They don't bury the lead. When someone asks a question, they give the answer immediately, and then - if needed - provide the context. Most people do it backwards."
> - Ian McAllister (ex-Amazon, Uber, Airbnb) on Lenny's Podcast

---

## Why This Matters

When you provide context first:
- Stakeholders tune out waiting for the point
- They form their own conclusions before you get there
- You seem uncertain or unprepared
- Trust erodes slowly over time

When you answer first:
- Stakeholders immediately know where you stand
- They can choose how much context they need
- You seem confident and decisive
- Trust builds with every interaction

---

## The Problem

Most PMs (and most people) provide context before answering. This creates confusion and slows down decision-making.

**Bad Pattern:**
> "So, we've been looking at the data, and there are a few things happening. First, we noticed that engagement is down, which could be related to the recent changes we made. Also, we're seeing some interesting patterns in the user feedback. What do you think we should do?"

**Good Pattern:**
> "We should pause the experiment. Engagement dropped 15% after the change, and user feedback shows confusion. Here's what we're seeing..."

---

## The Framework: BLUF (Bottom Line Up Front)

BLUF is a military communication technique that Ian McAllister adapted for product management. It forces you to lead with the conclusion.

### Step 1: Identify the Exact Question
Before responding, ask yourself:
- What is the person really asking?
- What decision do they need to make?
- What action do they need to take?
- **Critical:** Are they asking the question I think they're asking, or an adjacent one?

### Step 2: Answer First (BLUF)
- Answer in the first sentence
- Be direct and specific
- Use action language ("We should...", "The answer is...", "I recommend...")
- **No hedging:** Avoid "I think..." or "It might be..." unless truly uncertain

### Step 3: Provide Context
- After answering, explain why
- Share supporting data
- Add nuance and caveats
- **Only if needed:** Ask "Do you want more detail?" before diving deep

---

## BLUF Message Template

Use this when writing Slack updates, emails, or spoken responses.

```
Answer: <one sentence, direct response to the question>
Evidence:
- <data point 1>
- <data point 2>
- <data point 3 (optional)>
Recommendation: <one sentence on what should happen next>
```

---

## The "Last Sentence" Test

Write your message, then read the last sentence. If that is the main point, move it to the top and delete redundant context.

**Before:**
"The team has been investigating the drop in trial starts. We looked at seasonality, traffic sources, and funnel changes. After analyzing the data, we found that the new pricing page is causing a 20% drop in trial starts."

**After:**
"The new pricing page is causing a 20% drop in trial starts."

Evidence:
- Trial starts dropped 20% since page launch (Feb 1)
- Traffic is flat, so it's not a volume issue
- Funnel drop-off increased at the pricing step

Recommendation: Revert to the old page while we investigate further.

---

## Examples

### Example 1: Status Update

**Question:** "How's the launch going?"

**Bad:**
> "Well, we've been monitoring the metrics, and there are some interesting things happening. The team has been working really hard, and we've seen some good early signals. There are a few areas we're watching..."

**Good:**
> "It's going well—we're on track to hit our target. We've seen 12% adoption in the first week, which is above our 10% goal. Here's what we're seeing..."

---

### Example 2: Decision Request

**Question:** "Should we build this feature?"

**Bad:**
> "That's a great question. Let me think about this. There are a few factors to consider. We've done some research, and users have mentioned this, but it's not the top priority. However, it could be valuable..."

**Good:**
> "No, not yet. It's not in our top 3 priorities, and we don't have evidence it solves a real problem. Here's why..."

---

### Example 3: Data Question

**Question:** "Why did retention drop?"

**Bad:**
> "So, retention is a complex metric, and there are many factors that could influence it. We've been looking at the data, and there are some trends we're seeing. Let me walk you through what we found..."

**Good:**
> "New user onboarding is broken—Day 1 retention dropped 20% after we changed the flow. Here's the data..."

---

## Common Traps (and Fixes)

### Trap 1: "Let me give you some context..."
**Why it happens:** You want them to understand your thinking.  
**Why it fails:** They're waiting for the point.  
**Fix:** Give the answer, then offer: "Happy to share the context if helpful."

### Trap 2: "It's complicated..."
**Why it happens:** The situation is complex.  
**Why it fails:** Sounds like you don't understand it yourself.  
**Fix:** "The short answer is X. The full picture is more nuanced - want me to walk through it?"

### Trap 3: "I'm not sure, but..."
**Why it happens:** You don't want to be wrong.  
**Why it fails:** Undermines your credibility before you answer.  
**Fix:** State your best assessment with confidence, then caveat: "Based on current data. I'll confirm by EOD."

### Trap 4: Building the story
**Why it happens:** You want them to reach your conclusion.  
**Why it fails:** They might reach a different conclusion.  
**Fix:** Lead with your conclusion, then invite questions.

---

## Practice Questions

Before every communication, ask:
- [ ] What is the EXACT question being asked?
- [ ] What's my answer in one sentence?
- [ ] Am I starting with the answer or with context?

---

## Common Mistakes

### Mistake 1: Answering a Different Question
**Problem:** You answer what you think they should ask, not what they actually asked.
**Fix:** Repeat the question back to yourself before answering.

### Mistake 2: Being Vague
**Problem:** "It depends" or "We should consider..."
**Fix:** Pick a position. Even if you're uncertain, say "I'm not sure yet, but here's what I know..."

### Mistake 3: Over-Explaining
**Problem:** Providing too much context before the answer.
**Fix:** Answer first, then ask "Do you want more detail?"

---

## Self-Grading Rubric

After each communication, grade yourself:

**A:** Answered the exact question in the first sentence. No follow-up questions needed.
**B:** Answered the question, but took 2-3 sentences. Minor follow-up questions.
**C:** Answered eventually, but provided context first. Multiple follow-up questions.
**D:** Didn't clearly answer the question. Person had to ask again.
**F:** Completely missed the question or answered something else.

---

## Building the Habit

### Week 1: Awareness
- Before every meeting, identify the exact question
- Note when you're about to provide context first
- Catch yourself mid-sentence if needed

### Week 2: Practice
- Force yourself to answer first, even if it feels abrupt
- Ask for feedback: "Did I answer your question?"
- Self-grade after each communication

### Week 3: Refinement
- Make it natural and conversational
- Still answer first, but make it flow
- Continue self-grading

---

## Next Steps

1. **Practice today:** In your next meeting, answer first
2. **Self-grade:** After each communication this week
3. **Move to:** `02-Impact-Translation.md` once this feels natural

---

## Practice Exercises

### Exercise 1: Rewrite This Message

**Original:**
> "I've been looking into the onboarding drop-off issue. It's interesting because the data shows different patterns across segments. New users from paid ads seem to drop off at step 3, while organic users drop off at step 5. I think the paid users might not have strong intent. Anyway, the biggest issue is that step 3 requires email verification, and 40% of paid users never complete it."

**Your Rewrite:**  
[Write your answer-first version here]

<details>
<summary>See example answer</summary>

"Email verification at step 3 is causing 40% of paid users to drop off."
Key findings:

- Paid users: 40% drop at step 3 (email verification)
- Organic users: Only 15% drop at step 3
- Step 3 is the biggest single drop-off point

Recommendation: A/B test delayed verification (after step 5) for paid users.

</details>

### Exercise 2: The Meeting Update

You're in a meeting and asked: "How's the feature launch going?"  
Write an answer-first response (3 sentences max):

[Your answer here]

### Exercise 3: Daily Practice

For the next 3 days:

Before sending any message, check: Is my answer in the first sentence?  
If not, rewrite it.  
Track how many times you catch yourself.

Day 1: __ messages rewritten  
Day 2: __ messages rewritten  
Day 3: __ messages rewritten

---

## Checklist Before Sending

- [ ] Is my answer in the first sentence?
- [ ] Would they know the main point if they only read sentence one?
- [ ] Is my evidence in bullets, not paragraphs?
- [ ] Did I include a recommendation or next step?
- [ ] Did I delete unnecessary context?

---

## Real-World Examples

> Based on actual feedback: "Answer the exact question being asked, not adjacent ones"

### Example 1: TikTok Slideshow Feature Question

**The Situation:**
Leadership asks in a meeting: "Should we prioritize TikTok slideshow support?"

**What Happened (Before):**
> "So, TikTok has been growing a lot, and slideshows are becoming more popular. We've seen some merchants asking about this, and there's potential for engagement. The technical complexity is moderate, and we'd need to consider the content creation flow. There are also some UX considerations..."

**What to Do Instead (After):**
> "Yes, we should prioritize it for Q2. TikTok slideshows drive 40% higher engagement than static posts, and 3 of our top 10 merchants have requested this. Here's why it makes sense now..."

**Key Takeaway:** They asked "should we prioritize" — answer yes/no with the reason, not a tour of your research.

---

### Example 2: Answering Adjacent Questions

**The Situation:**
Manager asks: "What's the activation rate for new merchants this week?"

**What Happened (Before):**
> "We've been tracking activation closely. The funnel has a few stages, and we're seeing some drop-off at the integration step. Also, we noticed that merchants from different channels behave differently. The onboarding flow might need some work..."

**What to Do Instead (After):**
> "32%, down from 38% last week. The drop is from paid acquisition merchants—they're 15% lower than organic. Here's the breakdown..."

**Key Takeaway:** The question was "what's the rate" — give the number first, then context.

---

### Example 3: Trial Conversion Impact Question

**The Situation:**
Stakeholder asks: "What's the impact on trial conversions?"

**What Happened (Before):**
> "So we've been tracking this for a few weeks now, and the data shows some interesting patterns. The cohort from October had different behavior than September, and we noticed that email-onboarded users tend to convert at different rates. There are also some seasonal factors we're seeing..."

**What to Do Instead (After):**
> "12% lift in trial conversions, adding ~$15K MRR. This is based on October cohort data. The effect is stronger for email-onboarded users (18%) vs. organic (8%). I recommend we scale this to 100% of traffic next week."

**Key Takeaway:** They asked "what's the impact" — give the number and recommendation first, then supporting details.

---

### Example 4: Status Update Question

**The Situation:**
Manager asks: "How's the launch going?"

**What Happened (Before):**
> "Well, we've been monitoring the metrics, and there are some interesting things happening. The team has been working really hard, and we've seen some good early signals. There are a few areas we're watching..."

**What to Do Instead (After):**
> "It's going well—we're on track to hit our target. We've seen 12% adoption in the first week, which is above our 10% goal. Here's what we're seeing..."

**Key Takeaway:** They asked "how's it going" — give the status (good/bad/on track) first, then metrics.

---

## Practice Exercise: Self-Check Your Last 3-5 Communications

Review your last 3-5 emails, Slack messages, or meeting notes:

1. **Identify the question** that was asked (or implied)
2. **Find your answer** — where did you actually answer it?
3. **Count the sentences** before your answer
4. **Grade yourself:** A/B/C/D/F

**Pattern Recognition:**
- If you consistently answer after 2+ sentences → Focus on Week 1 practice
- If you answer adjacent questions → Focus on identifying the exact question
- If you hedge ("I think...", "It might...") → Practice being more direct

---

**Remember:** Answer first, then explain. It's counterintuitive but powerful.
